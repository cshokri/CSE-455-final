<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@400;600&display=swap" rel="stylesheet">
    <title>CSE 455 Final</title>
</head>
<body>
    <h1>CSE 455 Final</h1>
    <h3>By Cameron Shokri</h3>
    <div class="section">
        <h2>Problem Description</h2>
        <p>
            For my project I took part of the Kaggle bird classification competition. The task was to identify birds 
            from a given test dataset that contained a large number of bird images. There are 555 different types of birds
            in the test dataset and each group is scored based on the percentage of correct bird guesses. So whichever group
            classified the most number of birds correctly would win the competition. The Kaggle competition provided a training
            dataset with images and labels as well as the test dataset with only the images.
        </p>
    </div>
    <div class="section">
        <h2>Video</h2>
    </div>
    <div class="section">
        <h2>Previous work</h2>
        <p>
            I used PyTorch so I was able to reference the 
            <a href="https://github.com/huggingface/pytorch-image-models#getting-started-documentation">image models GitHub repository</a>.
            I went through the getting started part of the README which led me to using <i>timm</i> which is an open-source collection of
            PyTorch image models. I then used the <b>resnet50</b> and <b>resnet50d</b> pretrained models. I also referenced the documentation at
            <a href="https://huggingface.co/docs/hub/timm">huggingface</a> and the corresponding
            <a href="https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055">Getting Started</a> article.
            I also referenced the <a href="https://colab.research.google.com/drive/1EBz4feoaUvz-o_yeMI27LEQBkvrXNc_4?usp=sharing#scrollTo=vw2LBA8_WzPj">transfer learning collab</a> 
            for setting up the code to train a model.
        </p>
    </div>
    <div class="section">
        <h2>My approach</h2>
        <p>
            My approach was to use a pretrained model and do transfer learning on it for the birds training dataset. I did this by reinitializing the final 
            fully connected layer and then training the model on the training dataset. I first did this by following the collab, but the performance was
            around 56% accuracy so I needed to figure what would push me to higher accuracy. So I first tried with playing around with how the data was being
            transformed, I found that the horizontal flip helped performance by making it harder for the model to over fit to the training data. Changing the
            resize to 256 instead of 128 also improved performance. After this I realized that I was using resnet18 and there was a larger model called resnet50,
            so I ended up switching to that. However, I did run into "out of memory" issues, so I had to drop the batch size to 64. I also had to get the number 
            of features from the final layer to use when I reinitialized it since this number was different from resnet18. I trained for 13 epochs and on the 
            last epoch I set the learning rate to 0.001 so the model wouldn't try to learn something completely new on the last epoch and just squeeze out as much 
            performance out of it.
        </p>
        <p>
            My next big leap was using the resnet50d model from timm. I chose this model since from all the image classification models this one was
            in the top 10 performers on the ImageNet-1k dataset and it was similar to the resnet50 model that had already performed well. 
            Initially, I struggled to get any performance better than what I already had as I followed 
            the getting started article and the training time was over 6 hours for worse accuracy. I tried tweaking hyperparameters and data transformations, but 
            nothing made any substantial impact on the accuracy. Then I went and read through the documentation and it said that I should transform my data 
            in similar fashion to how the model was initially trained, so I just followed that and it slightly improved performance. What made the difference 
            was changing the center crop to a random crop and adding the random horizontal flipping. I was able to train for 13 epochs before overfitting 
            became a problem, this is what I did to get my best performing model.<br>
            <b>Code can be found here: </b><a href="https://github.com/cshokri/CSE-455-final/blob/main/BirdTrainer.py">https://github.com/cshokri/CSE-455-final/blob/main/BirdTrainer.py</a>
        </p>
    </div>
    <div class="section">
        <h2>Datasets</h2>
        <p>
            I only used the training dataset and all the other files that came from the <a href="https://www.kaggle.com/competitions/birds23sp/data">Kaggle competition</a>. 
            I didn't want to try to add my own bird images and label them since I thought that the given dataset was sufficient. Also, I don't know much about 
            birds and I don't want to contaminate my dataset with the wrong species of birds.
        </p>
    </div>
    <div class="section">
        <h2>Results</h2>
        <p>
            These results are from my submissions to the Kaggle competition.<br><br>
            <b>Highest Accuracy Using resnet50d: 85.75%</b> (my highest accuracy in the competition)<br>
            <b>Highest Accuracy Using resnet50: 83.65%</b><br><br>
        </p>
        <p>
            At the moment of writing this I am second place in the competition. I struggled to get past 80% accuracy when initially working with the 
            resnet50d model as everything I tried made little difference. Eventually getting the accuracy by changing the transforms on the data which helped 
            with avoiding overfitting. This was obvious since the model was overfitting at 7 epochs before (accuracy was dropping if I trained for more epochs)
            while now it was overfitting after 13 epochs. This was the same pattern as resnet50 so I figured that a lot of the accuracy gains I was going to
            make were from the transformations applied to the dataset.
        </p>
    </div>
    <div class="section">
        <h2>Discussion</h2>
        <ul>
            <li>
                <div class="question"><b>What problems did you encounter?</b></div>
                <p class="answer">
                    I initially struggled with getting the project up and running even though I was following along with the transfer learning collab.
                    The issue ended up being with the formatting of the csv file which after changing, fixed the errors. I also had errors when using
                    resnet50 as the number of features was different than resnet18, so I had to figure out how to get that from the final layer before
                    I reinitialized it. Then there was the gpu running out of memory issue which I fixed by reducing the batch size to 64.
                </p>
            </li>
            <li>
                <div class="question"><b>Are there next steps you would take if you kept working on the project?</b></div>
                <p class="answer">
                    I would probably spend more time researching about classification models, what works, what doesn't, and what are best practices. I would 
                    also try to use some of the other pretrained models to see how they performed. I just tried to stick with the limited knowledge I had 
                    as I didn't want to potentially waste time trying something new when I could still improve my accuracy with what I already knew.
                </p>
            </li>
            <li>
                <div class="question"><b>How does your approach differ from others? Was that beneficial?</b></div>
                <p class="answer">
                    Well I don't know what approaches other people went with, but assuming a lot of people followed the collabs then I would say that
                    switching models is a large part of what helped me break away from everyone else. I also tried to get as much performance by slightly
                    tweaking hyperparameters. I believe my efforts were beneficial as I am currently in second place in the competition.
                </p>
            </li>
        </ul>
    </div>

</body>
</html>